# -*- coding: utf-8 -*-
"""Ciphar10

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FPqLm0KGJ8c7lA7ISVz_kPLChOkGBZlK
"""

import numpy as np
from matplotlib import pyplot as plt
import glob
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC
import os
import platform
from six.moves import cPickle as pickle

!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
!ls

!ls

!tar -xvf cifar\-10\-python.tar.gz

def load_pickle(f):
    version = platform.python_version_tuple()
    if version[0] == '2':
        return  pickle.load(f)
    elif version[0] == '3':
        return  pickle.load(f, encoding='latin1')
    raise ValueError("invalid python version: {}".format(version))
    
def load_CIFAR_batch(filename):
  """ load single batch of cifar """
  with open(filename, 'rb') as f:
    datadict = load_pickle(f)
    X = datadict['data']
    Y = datadict['labels']
    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype("float")
    Y = np.array(Y)
    return X, Y

def load_CIFAR10(ROOT):
  """ load all of cifar """
  xs = []
  ys = []
  for b in range(1,6):
    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))
    X, Y = load_CIFAR_batch(f)
    xs.append(X)
    ys.append(Y)    
  Xtr = np.concatenate(xs)
  Ytr = np.concatenate(ys)
  del X, Y
  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))
  return Xtr, Ytr, Xte, Yte

train_images,train_labels,test_images,test_labels = load_CIFAR10('cifar-10-batches-py')
print (len(train_images))
print (len(test_images))

!pip install opencv-python==3.3.0.10 opencv-contrib-python==3.3.0.10
import cv2

# # Finding interest points of train images and appending them to a numpy array

sift = cv2.xfeatures2d.SIFT_create()

l_train = []
train_images = train_images.astype('uint8')
test_images = test_images.astype('uint8')

kp,des9 = sift.detectAndCompute(train_images[0],None)
l_train.append(len(des9))
des= []
des.append(des9)

i=1
p = len(train_images)
while(i<p):
#     print (i)
    kp1,des1 = sift.detectAndCompute(train_images[i],None)
    if des1 is None:
        train_images = np.delete(train_images,i,0)
        train_labels = np.delete(train_labels,i,0)
        p = p-1
        i=i-1
    else:
        l_train.append(len(des1))
        kp = np.hstack((kp,kp1))
#         des=np.vstack((des,des1))
        des.append(des1)
    i+=1
    print(i)

print (len(train_images))

l_test = []
test_images = test_images.astype('uint8')
kp2,des6 = sift.detectAndCompute(test_images[0],None)
des2 =[]
des2.append(des6)
l_test.append(len(des6))
for i in range(1,len(test_images)):
    kp1,des1 = sift.detectAndCompute(test_images[i],None)
    if des1 is None:
        des1 = np.zeros((1,128))
    l_test.append(len(des1))
    kp2 = np.hstack((kp2,kp1))
#     des2 = np.vstack((des2,des1))
    des2.append(des1)

des=[j for i in des for j in i]
des2=[j for i in des2 for j in i]

print (len(des))
print (len(des2))

k=100
kmeans = KMeans(n_clusters = k)
kmeans.fit(des)
ktr_labels = kmeans.labels_

kte_labels = kmeans.predict(des2)

train_hist = np.zeros((len(train_images),k))
j=0
count = 0
for i in range(len(train_images)):
    count = count+l_train[i]
    while(j<count):
        train_hist[i,ktr_labels[j]] = train_hist[i,ktr_labels[j]]+1
        j=j+1

test_hist = np.zeros((len(test_images),k))
j=0
count = 0
for i in range(len(test_images)):
    count = count+l_test[i]
    while(j<count):
        test_hist[i,kte_labels[j]] = test_hist[i,kte_labels[j]]+1
        j=j+1

plt.hist(train_hist.ravel(),256,[0,k])
plt.show()
plt.hist(test_hist.ravel(),256,[0,k])
plt.show()

stdSlr = StandardScaler().fit(train_hist)
train_hist = stdSlr.transform(train_hist)

stdSlr = StandardScaler().fit(test_hist)
test_hist = stdSlr.transform(test_hist)

clf = LinearSVC()
clf.fit(train_hist, np.array(train_labels))
print (" .....Accuracy........=  ",clf.score(test_hist,test_labels))

from sklearn.linear_model import LogisticRegression
log = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(train_hist, np.array(train_labels))
print (" .....Accuracy........=  ",log.score(test_hist,test_labels))